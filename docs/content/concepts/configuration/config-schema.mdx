---
title: Run Configuration | Dagster
description: Job run configuration allows providing parameters to jobs at the time they're executed.
---

# Run Configuration

Run configuration allows providing parameters to jobs at the time they're executed.

It's often useful to provide user-chosen values to Dagster jobs or software-defined assets at runtime. For example, you might want to choose what dataset an op runs against, or provide a connection URL for a database resource. Dagster exposes this functionality through a configuration API.

Various Dagster entities (ops, assets, resources) can be individually configured. When launching a job that executes (ops), materializes (assets), or instantiates (resources) a configurable entity, you can provide _run configuration_ for each entity. Within the function that defines the entity, you can access the passed-in configuration through the `config` parameter. Typically, the provided run configuration values correspond to a _configuration schema_ attached to the op/asset/resource definition. Dagster validates the run configuration against the schema and proceeds only if validation is successful.

A common use of configuration is for a [schedule](/concepts/partitions-schedules-sensors/schedules) or [sensor](/concepts/partitions-schedules-sensors/schedules) to provide configuration to the job run it is launching. For example, a daily schedule might provide the day it's running on to one of the ops as a config value, and that op might use that config value to decide what day's data to read.

---

## Relevant APIs

| Name                                                 | Description                                              |
| ---------------------------------------------------- | -------------------------------------------------------- |
| <PyObject module="dagster" object="ConfigSchema"  /> | See details with code examples in the API documentation. |

---

## Defining and accessing configuration for an op or asset

Configurable parameters accepted by an op or asset are specified by defining a config model extending `Config` and a `config` parameter to the corresponding function. Under the hood, these config models utilize [Pydantic](https://docs.pydantic.dev/), a popular Python library for data validation and serialization.

During execution, the specified config is accessed within the body of the op or asset using the `config` parameter.

Below we define a simple op and asset, each with a single configurable parameter, `person_name`:

```python file=/concepts/configuration/configurable_op_asset_resource.py startafter=start endbefore=end
from dagster._config.structured_config import Config


class MyOpConfig(Config):
    person_name: str


@op
def op_using_config(config: MyOpConfig):
    return f"hello {config.person_name}"


class MyAssetConfig(Config):
    person_name: str


@asset
def asset_using_config(config: MyAssetConfig):
    return f"hello {config.person_name}"
```

You can also build config into jobs, as described in [the Jobs documentation](/concepts/ops-jobs-graphs/jobs#configuring-jobs).

---

## Defining and accessing configuration for a resource

Configurable parameters for a resource are defined by specifying attributes for the resource class, which is itself a [Pydantic model](https://docs.pydantic.dev/usage/models/).

During execution, the specified attributes are accessible from the resource instance.

Below we define a simple resource with a configurable `url` parameter:

```python file=/concepts/configuration/configurable_op_asset_resource.py startafter=start_resource endbefore=end_resource
from dagster._config.structured_config import Resource


class ResourceUsingConfig(Resource):
    url: str

    def db_connection(self):
        return MyDatabaseConnection(self.url)
```

---

## Specifying runtime configuration

If you want to execute `op_using_config` or materialize `asset_using_config`, we'll need to provide values for the parameters specified in `config_schema`. How we provide these values depends on the interface we are using:

- [Python](#python)
- [Dagit](#dagit)
- [Command line](#command-line)

### Python

From the Python API, we can use the `run_config` argument for <PyObject object="JobDefinition" method="execute_in_process"/> or <PyObject object="materialize"/>. This takes a `RunConfig` object, within which we can supply config on a per-op or per-asset basis. The config is specified as a dictionary, with the keys corresponding to the op/asset names and the values corresponding to the config values.

```python file=/concepts/configuration/execute_with_config.py startafter=start_execute_with_config endbefore=end_execute_with_config dedent=4
from dagster._core.definitions.run_config import RunConfig

@job
def example_job():
    op_using_config()

job_result = example_job.execute_in_process(
    run_config=RunConfig(ops={"op_using_config": MyOpConfig(person_name="Alice")})
)

asset_result = materialize(
    [asset_using_config],
    run_config=RunConfig(assets={"asset_using_config": MyAssetConfig(person_name="Alice")}),
)
```

Config can alternatively be provided in the form of a dictionary, where configuration values for ops/assets are specified under `ops.<op_or_asset_name>.config`:

```python file=/concepts/configuration/execute_with_config.py startafter=start_execute_with_config_old endbefore=end_execute_with_config_old dedent=4
from dagster._core.definitions.run_config import RunConfig

@job
def example_job():
    op_using_config()

job_result = example_job.execute_in_process(
    run_config={"ops": {"op_using_config": {"config": {"person_name": "Alice"}}}}
)

asset_result = materialize(
    [asset_using_config],
    run_config={"ops": {"asset_using_config": {"config": {"person_name": "Alice"}}}},
)
```

### Dagit

From Dagit's [Launchpad](/concepts/dagit/dagit#launchpad-tab), we supply config as YAML using the config editor. The editor has typeahead, schema validation, and schema documentation. You can also click the "Scaffold Missing Config" button to generate dummy values based on the config schema. Note that a modal containing the launchpad editor will pop up if we attempt to materialize an asset with a defined `config_schema`:

<Image
alt="Config in Dagit"
src="/images/concepts/config-dagit.png"
width={3808}
height={2414}
/>

### Command line

When executing a job from Dagster's CLI with [dagster job execute](/\_apidocs/cli#dagster-job-execute), we can put config in a YAML file and pass the file path with the `--config` option:

```YAML file=/concepts/configuration/good.yaml
ops:
  op_using_config:
    config:
      person_name: Alice
```

```bash
dagster job execute --config my_config.yaml
```

---

## Validation

Dagster validates any provided run config against the corresponding config schemas. It will abort execution with a <PyObject object="DagsterInvalidConfigError"/> if validation fails. For example, both of the following will fail, because there is no `nonexistent_config_value` in the config schema:

```python file=/concepts/configuration/execute_with_config.py startafter=start_execute_with_bad_config endbefore=end_execute_with_bad_config dedent=4
@job
def example_job():
    op_using_config()

op_result = example_job.execute_in_process(
    run_config={"ops": {"op_using_config": {"config": {"nonexistent_config_value": 1}}}}
)

asset_result = materialize(
    [asset_using_config],
    run_config={"ops": {"asset_using_config": {"config": {"nonexistent_config_value": 1}}}},
)
```

---

## Examples

- [Passing secrets as configuration](#passing-secrets-as-configuration)
- [Passing configuration to multiple ops in a job](#passing-configuration-to-multiple-ops-in-a-job)

### Passing secrets as configuration

A common use case for configuration is passing secrets to connect to external services. Resources, which can be used to model connections to external services, accept secrets as configuration values. These secrets can be read from your environment variables:

```python file=/concepts/configuration/env_vars_config.py startafter=start_database_example endbefore=end_database_example
from dagster import StringSource, job, op, resource
from dagster._config.field_utils import EnvVar
from dagster._config.structured_config import Resource


class DatabaseClient(Resource):
    username: str
    password: str

    def execute_query(self, query):
        ...


@op
def get_one(database: DatabaseClient):
    database.execute_query("SELECT 1")


@job(
    resource_defs={
        "database": DatabaseClient(
            username=EnvVar("DATABASE_USERNAME"),
            password=EnvVar("DATABASE_PASSWORD"),
        )
    }
)
def get_one_from_db():
    get_one()
```

By providing secrets through environment variables, your secrets won't be visible in your code or Dagit's launchpad. Refer to the [Using environment variables and secrets in Dagster code guide](/guides/dagster/using-environment-variables-and-secrets) for more info and examples.

<Note>
  The{" "}
  <a href="/concepts/configuration/configured#specifying-per-environment-configuration">
    Configured API
  </a>{" "}
  page features an example of providing per-environment configuration.
</Note>

### Passing configuration to multiple ops in a job

If you want multiple ops to share values, You can use <PyObject module="dagster" object="make_values_resource" /> to pass the values via a resource and reference that resource from any op that needs it.

It defaults to <PyObject module="dagster" object="Any" /> type, meaning Dagster will accept any config value provided for the resource. We use `Injected` to indicate that the `file_dir` parameters are injected to our ops by the resource.

```python file=/concepts/configuration/make_values_resource_any.py startafter=start_file_example endbefore=end_file_example
from dagster._core.definitions.resource_output import Injected


@op
def add_file(context, file_dir: Injected[str]):
    filename = f"{file_dir}/new_file.txt"
    open(filename, "x", encoding="utf8").close()

    context.log.info(f"Created file: {filename}")


@op
def total_num_files(context, file_dir: Injected[str]):
    files_in_dir = os.listdir(file_dir)

    context.log.info(f"Total number of files: {len(files_in_dir)}")


@job(resource_defs={"file_dir": make_values_resource()})
def file_dir_job():
    add_file()
    total_num_files()
```

You can then specify your config under the `file_dir` resource:

```python file=/concepts/configuration/make_values_resource_run_config.py startafter=start_run_config_1 endbefore=end_run_config_1
result = file_dir_job.execute_in_process(
    run_config={"resources": {"file_dir": {"config": "/my_files/"}}}
)
```

If you want to provide different config values for each op within a job, you can also specify a structured schema using a `Resource` class:

```python file=/concepts/configuration/make_values_resource_config_schema.py startafter=start_file_example endbefore=end_file_example
from dagster._core.definitions.resource_output import Injected


class FileDirs(Resource):
    write_file_dir: str
    count_file_dir: str


@op
def write_file(context, file_dirs: FileDirs):
    filename = f"{file_dirs.write_file_dir}/new_file.txt"
    open(filename, "x", encoding="utf8").close()

    context.log.info(f"Created file: {filename}")


@op
def total_num_files(context, file_dirs: FileDirs):
    files_in_dir = os.listdir(file_dirs.count_file_dir)
    context.log.info(f"Total number of files: {len(files_in_dir)}")


@job(resource_defs={"file_dirs": FileDirs.configure_at_launch()})
def file_dirs_job():
    write_file()
    total_num_files()
```

You can specify run config like so:

```python file=/concepts/configuration/make_values_resource_run_config.py startafter=start_run_config_2 endbefore=end_run_config_2
result = file_dirs_job.execute_in_process(
    run_config={
        "resources": {
            "file_dirs": {
                "config": {
                    "write_file_dir": "/write_files/",
                    "count_file_dir": "/count_files/",
                }
            }
        }
    }
)
```

Or pass these values via a YAML file:

```YAML file=/concepts/configuration/make_values_resource_values.yaml
resources:
  file_dirs:
    config:
      write_file_dir: /write_files/
      count_file_dir: /count_files/
```

---

## See it in action

For more examples of jobs, check out the following in our [Hacker News example](https://github.com/dagster-io/dagster/tree/master/examples/project_fully_featured):

- [Config schema on a resource](https://github.com/dagster-io/dagster/blob/master/examples/project_fully_featured/project_fully_featured/resources/parquet_io_manager.py)
